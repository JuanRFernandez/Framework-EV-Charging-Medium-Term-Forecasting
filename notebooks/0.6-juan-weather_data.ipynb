{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gdfs():\n",
    "    # Get the current working directory\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # Define the relative paths to the data files\n",
    "    weather_path = os.path.join(cwd, '..', 'data', 'raw', 'weather', 'Scotland_2016-01-01_to_2019-12-31_hourly.csv')\n",
    "    time_series_gdf_path = os.path.join(cwd, '..', 'data', 'interim', 'train_gdf_forward_geocoded.csv')\n",
    "\n",
    "    # Load the dataframes\n",
    "    weather = pd.read_csv(weather_path)\n",
    "    time_series_gdf =  pd.read_csv(time_series_gdf_path)\n",
    "\n",
    "    return weather, time_series_gdf\n",
    "\n",
    "weather_df, time_series_gdf = load_gdfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Start DateTime to datetime format...\n",
      "Conversion successful for Start DateTime.\n",
      "Converting datetime to datetime format...\n",
      "Conversion successful for datetime.\n",
      "Extracting hour from Start DateTime...\n",
      "Extraction successful for Start DateTime.\n",
      "Extracting hour from datetime...\n",
      "Extraction successful for datetime.\n",
      "Converting Hour to the same data type in both dataframes...\n",
      "Conversion successful for Hour.\n",
      "Setting Hour as index...\n",
      "Hour set as index successfully.\n",
      "Setting Hour as index...\n",
      "Hour set as index successfully.\n",
      "Ensuring matching indices...\n",
      "Indices match successfully.\n",
      "Merging dataframes in chunks...\n",
      "Merging chunk 1 of 7...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def convert_to_datetime(df, column_name):\n",
    "    print(f\"Converting {column_name} to datetime format...\")\n",
    "    df[column_name] = pd.to_datetime(df[column_name])\n",
    "    print(f\"Conversion successful for {column_name}.\")\n",
    "    return df\n",
    "\n",
    "def extract_hour(df, column_name):\n",
    "    print(f\"Extracting hour from {column_name}...\")\n",
    "    df['Hour'] = df[column_name].dt.hour\n",
    "    print(f\"Extraction successful for {column_name}.\")\n",
    "    return df\n",
    "\n",
    "def set_index(df, column_name):\n",
    "    print(f\"Setting {column_name} as index...\")\n",
    "    df.set_index(column_name, inplace=True)\n",
    "    print(f\"{column_name} set as index successfully.\")\n",
    "    return df\n",
    "\n",
    "def merge_dataframes(df1, df2, method, chunk_size=10000):\n",
    "    print(\"Merging dataframes in chunks...\")\n",
    "    merged_df = pd.DataFrame()  # Create an empty dataframe to store the merged data\n",
    "    num_chunks = len(df1) // chunk_size + 1  # Calculate the number of chunks\n",
    "    for i in range(num_chunks):\n",
    "        try:\n",
    "            print(f\"Merging chunk {i+1} of {num_chunks}...\")\n",
    "            start = i * chunk_size\n",
    "            end = (i + 1) * chunk_size\n",
    "            chunk = df1.iloc[start:end]  # Get a chunk of df1\n",
    "            merged_chunk = pd.merge(chunk, df2, left_index=True, right_index=True, how=method)\n",
    "            merged_df = pd.concat([merged_df, merged_chunk])  # Add the merged chunk to the merged_df\n",
    "            print(f\"Chunk {i+1} merged successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while merging chunk {i+1}: {e}\")\n",
    "            return None\n",
    "    print(\"Merging completed.\")\n",
    "    return merged_df\n",
    "\n",
    "def fill_missing_values(df, method):\n",
    "    print(\"Filling missing values...\")\n",
    "    df.fillna(method=method, inplace=True)\n",
    "    print(\"Missing values filled successfully.\")\n",
    "    return df\n",
    "\n",
    "def convert_to_same_datatype(df1, df2, column_name):\n",
    "    print(f\"Converting {column_name} to the same data type in both dataframes...\")\n",
    "    df1[column_name] = df1[column_name].astype(str)\n",
    "    df2[column_name] = df2[column_name].astype(str)\n",
    "    print(f\"Conversion successful for {column_name}.\")\n",
    "    return df1, df2\n",
    "\n",
    "def ensure_matching_indices(df1, df2):\n",
    "    print(\"Ensuring matching indices...\")\n",
    "    common_indices = df1.index.intersection(df2.index)\n",
    "    df1 = df1.loc[common_indices]\n",
    "    df2 = df2.loc[common_indices]\n",
    "    print(\"Indices match successfully.\")\n",
    "    return df1, df2\n",
    "\n",
    "# Convert 'Start DateTime' and 'datetime' to datetime format\n",
    "time_series_gdf = convert_to_datetime(time_series_gdf, 'Start DateTime')\n",
    "weather_df = convert_to_datetime(weather_df, 'datetime')\n",
    "\n",
    "# Extract hour from 'Start DateTime' and 'datetime'\n",
    "time_series_gdf = extract_hour(time_series_gdf, 'Start DateTime')\n",
    "weather_df = extract_hour(weather_df, 'datetime')\n",
    "\n",
    "# Convert 'Hour' to the same data type in both dataframes\n",
    "time_series_gdf, weather_df = convert_to_same_datatype(time_series_gdf, weather_df, 'Hour')\n",
    "\n",
    "# Set 'Hour' as index\n",
    "time_series_gdf = set_index(time_series_gdf, 'Hour')\n",
    "weather_df = set_index(weather_df, 'Hour')\n",
    "\n",
    "# Ensure matching indices\n",
    "time_series_gdf, weather_df = ensure_matching_indices(time_series_gdf, weather_df)\n",
    "\n",
    "# Merge the dataframes\n",
    "merged_df = merge_dataframes(time_series_gdf, weather_df, 'left')\n",
    "if merged_df is None:\n",
    "    print(\"Merging failed. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "# Fill missing values\n",
    "merged_df = fill_missing_values(merged_df, 'ffill')\n",
    "\n",
    "# Reset index\n",
    "print(\"Resetting index...\")\n",
    "merged_df.reset_index(inplace=True)\n",
    "print(\"Index reset successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ev_charging_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
