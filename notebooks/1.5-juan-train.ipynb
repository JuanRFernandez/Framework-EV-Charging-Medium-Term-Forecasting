{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors as mcolors\n",
    "colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import matplotlib.dates as mdates\n",
    "from pandas.plotting import lag_plot, autocorrelation_plot\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf \n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "# Import necessary libraries\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FE / ML Libraries\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder, TargetEncoder, BinaryEncoder, CatBoostEncoder, HelmertEncoder, SumEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import f_classif, f_regression, mutual_info_classif, mutual_info_regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 10:51:50.354547: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-22 10:51:50.412969: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Import necessary libraries\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "DATA_PATH = os.path.join(cwd, '..', 'data')\n",
    "RAW_DATA_PATH = os.path.join(DATA_PATH, 'raw')\n",
    "PROCESSED_DATA_PATH = os.path.join(DATA_PATH, 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframes_from_csv(suffix='_4', directory='../data/interim/train'):\n",
    "    # Read the csv files and convert them to dataframes\n",
    "    X_train = pd.read_csv(os.path.join(directory, f'x_train{suffix}.csv'))\n",
    "    y_train = pd.read_csv(os.path.join(directory, f'y_train{suffix}.csv'))\n",
    "    X_val = pd.read_csv(os.path.join(directory, f'x_val{suffix}.csv'))\n",
    "    y_val = pd.read_csv(os.path.join(directory, f'y_val{suffix}.csv'))\n",
    "    X_test = pd.read_csv(os.path.join(directory, f'x_test{suffix}.csv'))\n",
    "    y_test = pd.read_csv(os.path.join(directory, f'y_test{suffix}.csv'))\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# Call the function\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataframes_from_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (44762, 28), (44762, 1)\n",
      "Validation shape: (9592, 28), (9592, 1)\n",
      "Test shape: (9591, 28), (9591, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs\n",
    "if X_train.isnull().values.any() or X_val.isnull().values.any() or X_test.isnull().values.any():\n",
    "    print(\"Data contains NaN values. Please clean the data.\")\n",
    "\n",
    "# Check shapes\n",
    "print(f\"Train shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1399/1399 [==============================] - 6s 4ms/step - loss: 76.3559 - mae: 6.5758 - val_loss: 94.4638 - val_mae: 8.2911\n",
      "Epoch 2/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 58.4781 - mae: 6.0775 - val_loss: 59.6724 - val_mae: 6.1300\n",
      "Epoch 3/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 55.2344 - mae: 5.9670 - val_loss: 51.8920 - val_mae: 5.6523\n",
      "Epoch 4/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 54.6416 - mae: 5.9533 - val_loss: 51.3715 - val_mae: 5.6275\n",
      "Epoch 5/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 54.4430 - mae: 5.9499 - val_loss: 51.3947 - val_mae: 5.6306\n",
      "Epoch 6/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 54.2992 - mae: 5.9445 - val_loss: 51.2613 - val_mae: 5.6243\n",
      "Epoch 7/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 54.2111 - mae: 5.9420 - val_loss: 51.2106 - val_mae: 5.6202\n",
      "Epoch 8/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 54.1470 - mae: 5.9400 - val_loss: 51.3537 - val_mae: 5.6292\n",
      "Epoch 9/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 54.0870 - mae: 5.9382 - val_loss: 51.1432 - val_mae: 5.6173\n",
      "Epoch 10/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 54.0488 - mae: 5.9359 - val_loss: 51.1521 - val_mae: 5.6124\n",
      "Epoch 11/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 54.0160 - mae: 5.9354 - val_loss: 51.1068 - val_mae: 5.6118\n",
      "Epoch 12/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.9989 - mae: 5.9339 - val_loss: 51.0765 - val_mae: 5.6100\n",
      "Epoch 13/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.9721 - mae: 5.9327 - val_loss: 51.0571 - val_mae: 5.6098\n",
      "Epoch 14/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.9473 - mae: 5.9312 - val_loss: 51.1121 - val_mae: 5.6168\n",
      "Epoch 15/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.9318 - mae: 5.9306 - val_loss: 51.1441 - val_mae: 5.6183\n",
      "Epoch 16/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.9310 - mae: 5.9324 - val_loss: 51.0503 - val_mae: 5.6078\n",
      "Epoch 17/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.9053 - mae: 5.9316 - val_loss: 51.0471 - val_mae: 5.6087\n",
      "Epoch 18/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.8953 - mae: 5.9299 - val_loss: 51.0826 - val_mae: 5.6067\n",
      "Epoch 19/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.8944 - mae: 5.9299 - val_loss: 51.0878 - val_mae: 5.6143\n",
      "Epoch 20/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.8607 - mae: 5.9283 - val_loss: 51.0471 - val_mae: 5.6062\n",
      "Epoch 21/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.8827 - mae: 5.9291 - val_loss: 51.0660 - val_mae: 5.6085\n",
      "Epoch 22/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.8666 - mae: 5.9301 - val_loss: 51.0571 - val_mae: 5.6097\n",
      "Epoch 23/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.8527 - mae: 5.9281 - val_loss: 51.0596 - val_mae: 5.6134\n",
      "Epoch 24/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.8404 - mae: 5.9276 - val_loss: 51.0748 - val_mae: 5.6137\n",
      "Epoch 25/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.8396 - mae: 5.9269 - val_loss: 51.0683 - val_mae: 5.6064\n",
      "Epoch 26/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.8293 - mae: 5.9269 - val_loss: 51.1332 - val_mae: 5.6107\n",
      "Epoch 27/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.8278 - mae: 5.9272 - val_loss: 51.0567 - val_mae: 5.6075\n",
      "Epoch 28/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.8250 - mae: 5.9266 - val_loss: 51.1008 - val_mae: 5.6100\n",
      "Epoch 29/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.7992 - mae: 5.9253 - val_loss: 51.5471 - val_mae: 5.6394\n",
      "Epoch 30/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.8005 - mae: 5.9258 - val_loss: 51.1805 - val_mae: 5.6205\n",
      "Epoch 31/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.7939 - mae: 5.9268 - val_loss: 51.1373 - val_mae: 5.6182\n",
      "Epoch 32/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.7900 - mae: 5.9243 - val_loss: 51.0584 - val_mae: 5.6058\n",
      "Epoch 33/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.7866 - mae: 5.9250 - val_loss: 51.1541 - val_mae: 5.6194\n",
      "Epoch 34/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.7831 - mae: 5.9244 - val_loss: 51.0545 - val_mae: 5.6118\n",
      "Epoch 35/50\n",
      "1399/1399 [==============================] - 4s 3ms/step - loss: 53.7687 - mae: 5.9240 - val_loss: 51.2618 - val_mae: 5.6252\n",
      "Epoch 36/50\n",
      " 477/1399 [=========>....................] - ETA: 2s - loss: 53.2360 - mae: 5.8893"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def build_train_best_model(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Build, compile, and train the best model based on optimized hyperparameters.\n",
    "    Then, plot the learning curves.\n",
    "    \"\"\"\n",
    "    # Build the best model\n",
    "    best_model = models.Sequential([\n",
    "        layers.Dense(416, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Compile the best model\n",
    "    best_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    # Train the best model\n",
    "    history = best_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,  # You can adjust this based on your observations\n",
    "        validation_data=(X_val, y_val)\n",
    "    )\n",
    "    \n",
    "    # Plotting learning curves\n",
    "    plot_learning_curve(history)\n",
    "\n",
    "def plot_learning_curve(history):\n",
    "    # Plotting accuracy and validation accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['mae'], label='Training MAE')\n",
    "    plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    plt.title('Model MAE')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting loss and validation loss\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "build_train_best_model(X_train, y_train, X_val, y_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ev_charging_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
